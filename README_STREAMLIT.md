# Female Foundry Chatbot

A lightweight chatbot experience styled after Chatbase: a floating popup widget with guided options, powered by a FastAPI backend and a static HTML/CSS/JS frontend. The assistant serves curated Female Foundry insights without relying on Streamlit.

## ğŸš€ Quick Start (Local)

```bash
# Install dependencies
pip install -r requirements.txt

# Start the FastAPI server (served with uvicorn)
uvicorn server:app --reload
```

Open your browser at **http://localhost:8000**. The landing page is served from `frontend/index.html` and communicates with the API under `/api`.

## ğŸ“¦ Deployment Snapshot

- The backend lives in `server.py` (FastAPI + in-memory session store).
- Static assets (HTML/CSS/JS) are located in `frontend/` and are mounted by FastAPI at the root path.
- The chat popup calls:
  - `POST /api/session` to start a session.
  - `POST /api/chat` to send a user message and receive bot replies/options.
  - `POST /api/session/{id}/reset` to restart the flow.
- No Streamlit runtime or `.streamlit` secrets are required.

For hosting you can deploy the same app on any service that runs uvicorn/gunicorn (Render, Railway, Fly.io, etc.). Make sure static files in `frontend/` are shipped with the service.

## ğŸ“ Project Structure

```
llm-mvp/
â”œâ”€â”€ server.py            # FastAPI application and chat logic
â”œâ”€â”€ requirements.txt     # Python dependencies (FastAPI + uvicorn)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html       # Landing page + chat popup markup
â”‚   â”œâ”€â”€ styles.css       # Chatbase-style design system
â”‚   â””â”€â”€ app.js           # Frontend logic hitting the /api endpoints
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ index.json       # FAQ/Index database
â”‚   â””â”€â”€ logs.json        # (Reserved for future logging, gitignored)
â””â”€â”€ DEPLOYMENT.md        # Deployment checklist (update to match FastAPI stack)
```

## âœ¨ Features

- Chatbase-inspired popup UI (floating launcher, popup card, clean typography)
- Guided menu: name capture â†’ top-level choices â†’ sub-options â†’ bullet summaries
- Curated bullet responses using `data/index.json`
- Session reset / restart controls built into the header
- Simple REST API you can embed anywhere (Wix, static sites, SPAs)

## ğŸ“ Notes

- All responses are deterministic summariesâ€”no OpenAI key required. Swap in LLM calls inside `handle_message` if desired.
- Sessions are stored in memory; wire up Redis or a database if you need persistence at scale.
- The frontend expects bullet responses as HTML lists. Use `format_bot_message()` when extending the backend to keep formatting consistent.

